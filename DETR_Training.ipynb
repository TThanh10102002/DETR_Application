{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DjRW9OY2c8Ma",
        "outputId": "f826d901-4ff7-4d9a-d698-681481847867"
      },
      "outputs": [],
      "source": [
        "#from google.colab import drive\n",
        "#drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OQCKoMMYwwEk",
        "outputId": "14783b73-d78a-4de9-81c6-4b9e247285cb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "time: 0 ns (started: 2023-06-30 15:54:36 +07:00)\n"
          ]
        }
      ],
      "source": [
        "%load_ext autotime"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "QPWw2bVcfKRH",
        "outputId": "7d44cf27-223a-4aaa-b754-59ee77c8563c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'2.0.0+cu117'"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "time: 0 ns (started: 2023-06-30 15:54:38 +07:00)\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "torch_version = torch.__version__\n",
        "assert float(torch_version[:3]) >= 1.5\n",
        "torch_version"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9MPotIn-fdNa",
        "outputId": "56c0cab7-62a2-4cdd-a38b-2351c1120df9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "WindowsPath('d:/NC_LAB/Trash_Classification/Code/DETR')"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "time: 16 ms (started: 2023-06-30 15:54:40 +07:00)\n"
          ]
        }
      ],
      "source": [
        "from pathlib import Path as p; p.cwd()  # make sure we know where we are"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0vRVg_s_gI5-",
        "outputId": "74cfaa1a-67ac-4d13-acab-c202c01e03cb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Volume in drive D is New Volume\n",
            " Volume Serial Number is 02E1-90BB\n",
            "\n",
            " Directory of d:\\NC_LAB\\Trash_Classification\\Code\\DETR\n",
            "\n",
            "06/29/2023  10:50 AM    <DIR>          .\n",
            "06/28/2023  10:05 AM    <DIR>          ..\n",
            "06/29/2023  09:44 AM    <DIR>          detr\n",
            "06/28/2023  04:27 PM    <DIR>          DETR_Output\n",
            "06/30/2023  03:54 PM            20,874 DETR_Training.ipynb\n",
            "06/29/2023  10:50 AM       166,595,797 detr-r50_training.pth\n",
            "06/28/2023  04:34 PM       166,618,694 detr-r50-e632da11.pth\n",
            "06/29/2023  10:50 AM    <DIR>          logdirs\n",
            "01/29/2022  09:10 AM    <DIR>          splits_final_deblurred\n",
            "06/28/2023  10:07 AM    <DIR>          training-detr\n",
            "06/28/2023  10:08 AM    <DIR>          zerowaste\n",
            "               3 File(s)    333,235,365 bytes\n",
            "               8 Dir(s)  74,612,064,256 bytes free\n",
            "time: 15 ms (started: 2023-06-30 15:54:47 +07:00)\n"
          ]
        }
      ],
      "source": [
        "%ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uFvbbEjjgRhW",
        "outputId": "ea211f69-4593-4f16-bebf-9e0ca33c24f5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "time: 703 ms (started: 2023-06-30 15:54:50 +07:00)\n"
          ]
        }
      ],
      "source": [
        "from PIL import Image\n",
        "import requests\n",
        "import matplotlib.pyplot as plt\n",
        "%config InlineBackend.figure_format = 'retina'\n",
        "\n",
        "from torch import nn\n",
        "import torchvision.transforms as T"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZwceKOaFhYqp",
        "outputId": "56cbb09a-c172-4ae6-d4ab-4ee6b47791a3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "dict"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "time: 125 ms (started: 2023-06-30 15:54:53 +07:00)\n"
          ]
        }
      ],
      "source": [
        "# Loading the weights, clipping out the two layers we want to train and saving it\n",
        "detr_model = torch.load(\"detr-r50-e632da11.pth\", map_location='cpu')\n",
        "type(detr_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from torchinfo import summary\n",
        "batch_size = 1\n",
        "summary(detr_model, input=(batch_size, 3, 600, 600))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "new_base = list(detr_model.children())\n",
        "print(new_base)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.nn import Linear\n",
        "new_base[1] = Linear(in_features=256, out_features = 5, bias=True)\n",
        "print(new_base[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(new_base)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "detr_state = torch.hub.load_state_dict_from_url(url=\"https://dl.fbaipublicfiles.com/detr/detr-r50-e632da11.pth\",\n",
        "                                                map_location=\"cpu\")\n",
        "type(detr_state)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "time: 188 ms (started: 2023-06-30 15:55:52 +07:00)\n"
          ]
        }
      ],
      "source": [
        "del detr_model['model']['class_embed.weight']\n",
        "del detr_model['model']['class_embed.bias']\n",
        "torch.save(detr_model, 'detr-r50_training.pth')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "d:\\NC_LAB\\Trash_Classification\\Code\\DETR\\detr\n",
            "time: 0 ns (started: 2023-06-30 15:57:55 +07:00)\n"
          ]
        }
      ],
      "source": [
        "%cd detr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "time: 2.64 s (started: 2023-06-30 15:59:11 +07:00)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "d:\\anaconda3\\python.exe: Error while finding module specification for 'main.py' (ModuleNotFoundError: __path__ attribute not found on 'main' while trying to find 'main.py'). Try using 'main' instead of 'main.py' as the module name.\n"
          ]
        }
      ],
      "source": [
        "!python -m main.py --dataset_file \"mycoco\" --coco_path \"D:/NC_LAB/Trash_Classification/Code/DETR/splits_final_deblurred/\" --output_dir \"D:/NC_LAB/Trash_Classification/Code/DETR/DETR_Output\" --resume \"D:/NC_LAB/Trash_Classification/Code/DETR/detr-r50_training.pth\" --lr 1e-5 --lr_backbone 1e-6 --epochs 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IxxxIYTHiQQh",
        "outputId": "abebf4e2-080c-4582-f68b-e53d42f28098"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'datasets'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_9448/2504820708.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdetr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mdetr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdatasets\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mbuild_dataset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mget_coco_api_from_dataset\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdetr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutil\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmisc\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mutils\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mdetr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_one_epoch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32md:\\NC_LAB\\Trash_Classification\\Code\\DETR\\detr\\datasets\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mcoco\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mbuild\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mbuild_coco\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32md:\\NC_LAB\\Trash_Classification\\Code\\DETR\\detr\\datasets\\coco.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mpycocotools\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmask\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mcoco_mask\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransforms\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mT\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'datasets'"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "time: 343 ms (started: 2023-06-30 15:56:27 +07:00)\n"
          ]
        }
      ],
      "source": [
        "import argparse\n",
        "import datetime\n",
        "import json\n",
        "import random\n",
        "import time\n",
        "from pathlib import Path\n",
        "\n",
        "import numpy as np\n",
        "from torch.utils.data import DataLoader, DistributedSampler\n",
        "\n",
        "import detr\n",
        "from detr.datasets import build_dataset, get_coco_api_from_dataset\n",
        "import detr.util.misc as utils\n",
        "from detr.engine import evaluate, train_one_epoch\n",
        "from detr.models import build_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1025XH43v7rk",
        "outputId": "15aea494-7189-4ffd-96ef-576c16d445df"
      },
      "outputs": [],
      "source": [
        "# Some basic setup:\n",
        "# Setup detectron2 logger\n",
        "import detectron2\n",
        "from detectron2.utils.logger import setup_logger\n",
        "setup_logger()\n",
        "\n",
        "# import some common libraries\n",
        "import numpy as np\n",
        "import os, cv2, random\n",
        "import io\n",
        "\n",
        "# import torch and torchvision\n",
        "from torchvision.models import resnet50\n",
        "import torchvision.transforms as T\n",
        "torch.set_grad_enabled(False);\n",
        "\n",
        "# import some common detectron2 utilities\n",
        "from detectron2 import model_zoo\n",
        "from detectron2.engine import DefaultPredictor\n",
        "from detectron2.config import get_cfg\n",
        "from detectron2.utils.visualizer import Visualizer\n",
        "from detectron2.data import MetadataCatalog, DatasetCatalog, MapDataset\n",
        "from detectron2.data.datasets import load_coco_json, register_coco_instances\n",
        "from pathlib import Path\n",
        "from detectron2.checkpoint import DetectionCheckpointer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9InvuUvSwVss",
        "outputId": "0d68de0a-935c-4062-9fea-01153a7cfbd5"
      },
      "outputs": [],
      "source": [
        "# if your dataset is in COCO format, this cell can be replaced by the following three lines:\n",
        "dataset_train_name = \"zero-waste-train\"\n",
        "dataset_val_name = \"zero-waste-val\"\n",
        "dataset_test_name = \"zero-waste-test\"\n",
        "\n",
        "\n",
        "from detectron2.data.datasets import register_coco_instances\n",
        "register_coco_instances(dataset_train_name, {}, \"D:/NC_LAB/Trash_Classification/Code/DETR/splits_final_deblurred/train/labels.json\", \"D:/NC_LAB/Trash_Classification/Code/DETR/splits_final_deblurred/train/data\")\n",
        "register_coco_instances(dataset_val_name, {}, \"D:/NC_LAB/Trash_Classification/Code/DETR/splits_final_deblurred/val/labels.json\", \"D:/NC_LAB/Trash_Classification/Code/DETR/splits_final_deblurred/val/data\")\n",
        "register_coco_instances(dataset_test_name, {}, \"D:/NC_LAB/Trash_Classification/Code/DETR/splits_final_deblurred/test/labels.json\", \"D:/NC_LAB/Trash_Classification/Code/DETR/splits_final_deblurred/test/data\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hhKG4mPgwc60",
        "outputId": "bb0758d5-6f2e-4bf9-b4b7-ccf92c4142a3"
      },
      "outputs": [],
      "source": [
        "# Train data\n",
        "waste_train_dict = load_coco_json(\"D:/NC_LAB/Trash_Classification/Code/DETR/splits_final_deblurred/train/labels.json\", \"D:/NC_LAB/Trash_Classification/Code/DETR/splits_final_deblurred/train/data\",\n",
        "                dataset_name=dataset_train_name)\n",
        "\n",
        "# Val data\n",
        "waste_val_dict = load_coco_json(\"D:/NC_LAB/Trash_Classification/Code/DETR/splits_final_deblurred/val/labels.json\", \"D:/NC_LAB/Trash_Classification/Code/DETR/splits_final_deblurred/val/data\",\n",
        "                dataset_name=dataset_val_name)\n",
        "\n",
        "# Test data\n",
        "waste_test_dict = load_coco_json(\"D:/NC_LAB/Trash_Classification/Code/DETR/splits_final_deblurred/test/labels.json\", \"D:/NC_LAB/Trash_Classification/Code/DETR/splits_final_deblurred/test/data\",\n",
        "                dataset_name=dataset_test_name)\n",
        "\n",
        "train_metadata = MetadataCatalog.get(dataset_train_name)\n",
        "test_metadata = MetadataCatalog.get(dataset_test_name)\n",
        "val_metadata = MetadataCatalog.get(dataset_val_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UDgQOaXRwkF0",
        "outputId": "b1ac1bf3-629a-41f2-c63f-2c95ffe8ba41"
      },
      "outputs": [],
      "source": [
        "from detectron2.data.transforms import ScaleTransform\n",
        "\n",
        "# Resize image in train_dict\n",
        "scale_transform = ScaleTransform(1080, 1920, 540, 960, \"nearest\")\n",
        "\n",
        "# Define the dataset mapper to apply the Scale transform\n",
        "def dataset_mapper(dataset_dict):\n",
        "    for d in dataset_dict:\n",
        "        # Apply the Scale transform to the image\n",
        "        image = d[\"file_name\"]\n",
        "        image = scale_transform.apply_image(image)\n",
        "\n",
        "        # Create a new dataset dictionary with the scaled image\n",
        "        d[\"file_name\"] = image\n",
        "\n",
        "    # Return the modified dataset dictionary\n",
        "    return dataset_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PaYG78xkwmYk",
        "outputId": "d4340998-d4d0-4651-95bb-1abf103c9b16"
      },
      "outputs": [],
      "source": [
        "dataset_train = MapDataset(DatasetCatalog.get(dataset_train_name), dataset_mapper)\n",
        "dataset_val = MapDataset(DatasetCatalog.get(dataset_val_name), dataset_mapper)\n",
        "dataset_test = MapDataset(DatasetCatalog.get(dataset_test_name), dataset_mapper)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "VVJS8fScxdFU",
        "outputId": "7403a45c-ed17-4268-b24f-53d0546e269d"
      },
      "outputs": [],
      "source": [
        "for d in random.sample(waste_train_dict, 3):\n",
        "    img = cv2.imread(d[\"file_name\"])\n",
        "    visualizer = Visualizer(img[:, :, ::-1], metadata=train_metadata, scale=0.5)\n",
        "    out = visualizer.draw_dataset_dict(d)\n",
        "    print(d[\"file_name\"])\n",
        "    print(f\"Actual image shape: {img.shape}\")\n",
        "    vis_image = out.get_image()\n",
        "\n",
        "    # Get the shape of the image\n",
        "    image_shape = vis_image.shape\n",
        "\n",
        "    print(f\"Scaled image shape: {image_shape}\")\n",
        "    plt.imshow(out.get_image()[:, :, ::-1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1aQ79RO9uz2Q",
        "outputId": "b616dd36-7a9c-4c17-d9b9-f86c1ad329b3"
      },
      "outputs": [],
      "source": [
        "dataset_file = \"mycoco\" # alternatively, implement your own coco-type dataset loader in datasets and add this \"key\" to datasets/__init__.py\n",
        "#dataDir = dataset_train\n",
        "dataDir='D:/NC_LAB/Trash_Classification/Code/DETR/splits_final_deblurred/' # should lead to a directory with a train2017 and val2017 folder as well as an annotations folder\n",
        "num_classes = 5 # this int should be the actual number of classes + 1 (for no class)\n",
        "\n",
        "outDir = 'D:/NC_LAB/Trash_Classification/Code/DETR/DETR_Output'\n",
        "resume = \"D:/NC_LAB/Trash_Classification/Code/DETR/detr-r50_training.pth\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9eZeZu4e8rgQ",
        "outputId": "008807e4-13fb-435e-e818-c1e5e0726969"
      },
      "outputs": [],
      "source": [
        "type(num_classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wV_8wwvWlpwF",
        "outputId": "6af8d096-dcda-4858-f90d-3628b662cd45"
      },
      "outputs": [],
      "source": [
        "!python -m D:/NC_Lab/Trash_Classification/Code/DETR/ main --dataset_file dataset_file --coco_path dataDir --output_dir outDir --resume resume --lr 1e-5 --lr_backbone 1e-6 --epochs 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
